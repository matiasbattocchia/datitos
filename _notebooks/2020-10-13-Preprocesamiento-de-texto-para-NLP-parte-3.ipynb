{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de texto para NLP (parte 3)\n",
    "> \"o(^x^)o Embeddings pre-entrenados\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Mat铆as Battocchia\n",
    "- categories: [nlp,pytorch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el art铆culo final de la serie preprocesamiento de texto para NLP. Los art铆culos anteriores son [parte 1](Preprocesamiento-de-texto-para-NLP-parte-1.html) y [parte 2](Preprocesamiento-de-texto-para-NLP-parte-2.html).\n",
    "\n",
    "En este nos vamos a focalizar en *embeddings* pre-entrenados. Los *embeddings* son un tema central en procesamiento del lenguaje y mucho se ha escrito al respecto. Ac谩 hay algunos enlaces para introducrise en el tema\n",
    "* [The illustrated Word2Vec](http://jalammar.github.io/illustrated-word2vec)\n",
    "* [CS224n presentaci贸n *word vectors*](http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture01-wordvecs1.pdf)\n",
    "* [CS224n trabajo pr谩ctico *word vectors*](http://web.stanford.edu/class/cs224n/assignments/a1_preview/exploring_word_vectors.html)\n",
    "\n",
    "y ac谩 dejamos algunos enlaces sobre c贸mo algunos *frameworks* abarcan el tema de este mismo art铆culo\n",
    "* [Keras](https://keras.io/examples/nlp/pretrained_word_embeddings)\n",
    "* [Gluon](https://gluon-nlp.mxnet.io/examples/word_embedding/word_embedding.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los embeddings son la primera capa en las redes neuronales que procesan texto. Mapean 铆ndices (a cada t贸ken le corresponde un 铆ndice, los 铆ndices corren de cero hasta `len(t贸kenes)`). Estamos mapeando enteros a vectores, a cada 铆ndice le corresponde un vector de palabra que codifica a la palabra. El mapeo se realiza por medio de una matriz que tiene tantas filas como 铆ndices y tantas columnas como la dimensi贸n de los vectores. Esta dimensi贸n es un hiperpar谩metro del modelo y b谩sicamente significa la cantidad de atributos con la que representaremos a las palabras. Elegir una fila de la matriz, y a cada 铆ndice/t贸ken le corresponde una fila) estamos rebanando la matriz de modo de quedarnos con un vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el resto de las capas de una red neuronal que no ha sido entrenada los pesos de la capa de *embeddings* se inicializan al azar. O sea que al seleccionar un vector de palabra obtenemos un vector con componentes aleatorios. La idea central de los *embeddings* es que las palabras adquieren significado a partir de las palabras que la rodean. Una vez que la red neural ha sido entrenada y que los componentes de los vectores de palabras no son azarosos sino que han capturado en mayor o menor medida el significado de las palabras, la distancia entre los vectores ([similitud del coseno](https://es.wikipedia.org/wiki/Similitud_coseno) es una forma de calcular la distancia entre vectores) de palabras similares es m谩s corta, es decir los *embeddings* est谩n m谩s cerca, que si cuando se consideran palabras con significados dis铆miles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las primeras t茅cnicas de transfencia de aprendizaje (*transfer learning*) fue utilizar *embeddings* pre-entrenados. La red neuronal con la que son entrenados y la que los utiliza con otros fines pueden tener arquitecturas bien distintas, comparten solamente los vectores de palabras, es decir la primera capa. Vimos que el armado del vocabulario es un asunto central y ser铆a extra帽o que adoptemos el mismo vocabulario que la red que se utiliz贸 para entrenar los *embeddings*; no es esto un problema mientras haya una intersecci贸n substancial entre el vocabulario que queremos utilizar y el que se utiliz贸 para los *embeddings*, ya que nos estamos limitando a este 煤ltimo, posiblemente entrenado con un corpus general (Wikipedia) mientras que el vocabulario que necesitamos posiblemente pertenezca a un corpus particular. Todos los t贸kenes que no est谩n en el vocabulario se denominan **fuera del vocabulario** (*out-of-vocabulary* u OOV) y requieren un tratamiento especial como ser ignorados/eliminados o mapeados a un t贸ken especial que codifique t贸kenes desconocidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los 铆ndices del vocabulario que crearemos tampoco ser谩 el mismo que los que se usaron para los vectores pre-entrenados. Por lo tanto la estrategia para obtener los pesos de la capa de vectores de palabra es la siguiente.\n",
    "\n",
    "1. Descargar los vectores pre-entrenados\n",
    "2. Obtener los vectores del vocabulario propio\n",
    "3. Ordenar los vectores seg煤n los 铆ndices propios\n",
    "4. Crear un tensor\n",
    "5. Inicializar los pesos de la capa de *embeddings*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargar los vectores pre-entrenados\n",
    "\n",
    "Los proyectos m谩s conocidos son\n",
    "* Word2Vec\n",
    "* [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
    "* [fastText](https://fasttext.cc/docs/en/support.html)\n",
    "\n",
    "Vamos a usar fastText por tener vectores para idioma espa帽ol y soporte para OOV. Primero instalamos el paquete de Python\n",
    "\n",
    "```bash\n",
    "pip install fasttext\n",
    "```\n",
    "\n",
    "y luego descargamos e inicializamos el modelo. Pesa unos 3,5 GB  as铆 que la descarga puede demorar. La dimensi贸n de los vectores de este modelo es 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "fasttext.util.download_model('es', if_exists='ignore')\n",
    "\n",
    "ft = fasttext.load_model('cc.es.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANTE**. Particularmente la carga de este modelo necesita de unos 12 GB de memoria RAM/swap, lo que me llev贸 a cerrar aplicaciones para liberar memoria. Para evitar pasar siempre por este paso, una vez que obtuve el tensor con los pesos necesarios lo salv茅 en un archivo; levantar este archivo es mucho m谩s liviano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener los vectores del vocabulario\n",
    "\n",
    "Redefinimos ligeramente la clase `Vocab` que fuimos escribiendo en las partes anteriores. Lo nuevo es la propiedad `vocabulario`, que devuelve la lista de t贸kenes del vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# versi贸n 5\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "class Vocab():\n",
    "    # ning煤n cambio aqu铆\n",
    "    @property\n",
    "    def 铆ndice_relleno(self):\n",
    "        return self.mapeo.get(self.t贸ken_relleno)\n",
    "    \n",
    "    # ning煤n cambio aqu铆\n",
    "    def __init__(self, t贸ken_desconocido='<unk>', t贸ken_relleno='<pad>', frecuencia_m铆nima=0.0, frecuencia_m谩xima=1.0,\n",
    "                 longitud_m铆nima=1, longitud_m谩xima=np.inf, stop_words=[], l铆mite_vocabulario=None):\n",
    "        \n",
    "        self.t贸ken_desconocido = t贸ken_desconocido\n",
    "        self.t贸ken_relleno = t贸ken_relleno\n",
    "        self.frecuencia_m铆nima = frecuencia_m铆nima\n",
    "        self.frecuencia_m谩xima = frecuencia_m谩xima\n",
    "        self.longitud_m铆nima = longitud_m铆nima\n",
    "        self.longitud_m谩xima = longitud_m谩xima\n",
    "        self.stop_words = stop_words\n",
    "        self.l铆mite_vocabulario = l铆mite_vocabulario\n",
    "    \n",
    "    # ning煤n cambio aqu铆\n",
    "    def reducir_vocabulario(self, lote):\n",
    "        contador_absoluto = Counter(chain(*lote))\n",
    "        \n",
    "        contador_documentos = Counter()\n",
    "        \n",
    "        for doc in lote:\n",
    "            contador_documentos.update(set(doc))\n",
    "        \n",
    "        # frecuencia m铆nima\n",
    "        if isinstance(self.frecuencia_m铆nima, int): # frecuencia de t贸ken\n",
    "            vocabulario_m铆n = [t贸ken for t贸ken, frecuencia in contador_absoluto.most_common() if frecuencia >= self.frecuencia_m铆nima]\n",
    "        else: # frecuencia de documento\n",
    "            vocabulario_m铆n = [t贸ken for t贸ken, frecuencia in contador_documentos.most_common() if frecuencia/len(lote) >= self.frecuencia_m铆nima]\n",
    "        \n",
    "        # frecuencia m谩xima\n",
    "        if isinstance(self.frecuencia_m谩xima, int): # frecuencia de t贸ken\n",
    "            vocabulario_m谩x = [t贸ken for t贸ken, frecuencia in contador_absoluto.most_common() if self.frecuencia_m谩xima >= frecuencia]\n",
    "        else: # frecuencia de documento\n",
    "            vocabulario_m谩x = [t贸ken for t贸ken, frecuencia in contador_documentos.most_common() if self.frecuencia_m谩xima >= frecuencia/len(lote)]\n",
    "\n",
    "        # intersecci贸n de vocabulario_m铆n y vocabulario_m谩x preservando el 贸rden\n",
    "        vocabulario = [t贸ken for t贸ken in vocabulario_m铆n if t贸ken in vocabulario_m谩x]\n",
    "\n",
    "        # longitud\n",
    "        vocabulario = [t贸ken for t贸ken in vocabulario if self.longitud_m谩xima >= len(t贸ken) >= self.longitud_m铆nima]\n",
    "        \n",
    "        # stop words\n",
    "        vocabulario = [t贸ken for t贸ken in vocabulario if t贸ken not in self.stop_words]\n",
    "        \n",
    "        # l铆mite\n",
    "        vocabulario = vocabulario[:self.l铆mite_vocabulario]\n",
    "        \n",
    "        return vocabulario\n",
    "        \n",
    "    def fit(self, lote):\n",
    "        vocabulario = []\n",
    "        \n",
    "        if self.t贸ken_relleno:\n",
    "            vocabulario.append(self.t贸ken_relleno)\n",
    "        \n",
    "        if self.t贸ken_desconocido:\n",
    "            vocabulario.append(self.t贸ken_desconocido)\n",
    "        \n",
    "        vocabulario += self.reducir_vocabulario(lote)\n",
    "        \n",
    "        self.mapeo = {t贸ken: 铆ndice for 铆ndice, t贸ken in enumerate(vocabulario)}\n",
    "\n",
    "        return self\n",
    "    \n",
    "    # ning煤n cambio aqu铆\n",
    "    def transform(self, lote):\n",
    "        if self.t贸ken_desconocido: # reemplazar\n",
    "            return [[t贸ken if t贸ken in self.mapeo else self.t贸ken_desconocido for t贸ken in doc] for doc in lote]\n",
    "        else: # ignorar\n",
    "            return [[t贸ken for t贸ken in doc if t贸ken in self.mapeo] for doc in lote]\n",
    "    \n",
    "    # ning煤n cambio aqu铆\n",
    "    def t贸kenes_a_铆ndices(self, lote):\n",
    "        lote = self.transform(lote)\n",
    "        \n",
    "        return [[self.mapeo[t贸ken] for t贸ken in doc] for doc in lote]\n",
    "    \n",
    "    # ning煤n cambio aqu铆\n",
    "    def 铆ndices_a_t贸kenes(self, lote):\n",
    "        mapeo_inverso = list(self.mapeo.keys())\n",
    "        \n",
    "        return [[mapeo_inverso[铆ndice] for 铆ndice in doc] for doc in lote]\n",
    "    \n",
    "    # ning煤n cambio aqu铆\n",
    "    def __len__(self):\n",
    "        return len(self.mapeo)\n",
    "    \n",
    "    @property\n",
    "    def vocabulario(self):\n",
    "        return list(v.mapeo.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el vocabulario como lo hicimos anteriormente (parte 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train.csv', sep='|')\n",
    "\n",
    "# hacemos una tokenizaci贸n muy simple\n",
    "def tokenizar(texto):\n",
    "    return texto.split()\n",
    "\n",
    "train_docs = [tokenizar(doc) for doc in df['Pregunta'].values]\n",
    "\n",
    "v = Vocab().fit(train_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde Python 3.7 est谩 garantizado que el orden del diccionario es el orden de inserci贸n. Por lo tanto el 贸rden de la lista `v.vocabulario` coincide con el del diccionario `v.mapeo` (ver implementaci贸n de `Vocab`). Tener claro el 贸rden / los 铆ndices de los t贸kenes es importante porque crearemos un tensor de *embeddings* al cu谩l accederemos mediante 铆ndices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '<unk>', 'de', 'el', 'la', 'tarjeta', 'que', 'para', 'un', 'me']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.vocabulario[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, el *embedding* del t贸ken `tarjeta` ser谩 `embeddings[5]` ya que el t贸ken est谩 en el quinto lugar del vocabulario (recordar que empezamos a contar por cero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La interfaz de fastText para obtener un vector a partir de un t贸ken es como la de un diccionario. As铆 luce un *embedding* de dimensi贸n 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06298134, -0.03280621,  0.03053921, -0.14426479, -0.04330583,\n",
       "        0.02782611,  0.04671088,  0.01322352, -0.00091936, -0.02005653,\n",
       "       -0.08679762, -0.00335382, -0.04299804,  0.03553167, -0.07989401,\n",
       "        0.00514562,  0.06741733, -0.01824431, -0.0627635 , -0.03652998,\n",
       "       -0.02327815, -0.06624147,  0.00762858,  0.04288524, -0.02111394,\n",
       "       -0.02724549,  0.01001478, -0.0437385 , -0.07554701,  0.00330107,\n",
       "       -0.00436452, -0.03166814, -0.02237143, -0.00398921, -0.00873911,\n",
       "        0.01801448,  0.06549975,  0.02997639,  0.04104616,  0.08769971,\n",
       "       -0.06594162, -0.01973427,  0.03386661, -0.05415446, -0.0547767 ,\n",
       "       -0.00098864, -0.00864553,  0.05127762,  0.02343957, -0.00937056,\n",
       "       -0.03792336,  0.06513872,  0.03453366,  0.00376538,  0.00911847,\n",
       "        0.03639029, -0.04959448, -0.10815199,  0.0189229 , -0.00545404,\n",
       "       -0.0441896 ,  0.05246361, -0.08793913,  0.01742068,  0.07848521,\n",
       "        0.00829239,  0.00512537, -0.00187416,  0.06793492, -0.0205775 ,\n",
       "        0.09385861,  0.06492148,  0.08256735, -0.01685029,  0.04042866,\n",
       "       -0.03420147, -0.01297663, -0.03008673,  0.06171214, -0.0073834 ,\n",
       "       -0.00952853, -0.07957197,  0.05753422, -0.00230803,  0.01646664,\n",
       "        0.00405738,  0.01874345, -0.01656639,  0.03835326,  0.00671893,\n",
       "        0.03538686, -0.05837374,  0.00655341, -0.06613984, -0.00893264,\n",
       "        0.01970789, -0.02059824, -0.01957787,  0.04642227, -0.03362621,\n",
       "       -0.03894996, -0.03437151, -0.0639662 , -0.00890221, -0.02950617,\n",
       "        0.030174  ,  0.00092385,  0.08426531, -0.00274815,  0.00948968,\n",
       "        0.04102866,  0.01430673,  0.01487885,  0.0998308 , -0.0284079 ,\n",
       "       -0.00470919,  0.03808989,  0.08536439,  0.03592137,  0.07948075,\n",
       "        0.0172466 , -0.07252405, -0.0107453 ,  0.0275656 ,  0.02603439,\n",
       "        0.01865727, -0.10967878,  0.04329263, -0.03052348,  0.01704779,\n",
       "       -0.05844689,  0.06367239,  0.00445418,  0.1319068 ,  0.02953896,\n",
       "        0.02432506,  0.04764185,  0.04224063, -0.05673009, -0.00072847,\n",
       "       -0.01646314,  0.0195642 ,  0.02678232, -0.02039818,  0.01072512,\n",
       "        0.03165798,  0.02296546,  0.03048908,  0.00605224,  0.03494508,\n",
       "       -0.03987421,  0.10772546,  0.05239586, -0.05665122, -0.04541425,\n",
       "       -0.03411638,  0.00866744, -0.10566777, -0.06131719, -0.0434983 ,\n",
       "        0.07758161, -0.05220485,  0.03249336, -0.12057097,  0.05518946,\n",
       "       -0.00267152, -0.0791545 ,  0.00928127, -0.03528287, -0.07231892,\n",
       "       -0.00943873,  0.02749985, -0.02224496,  0.001105  , -0.04838763,\n",
       "        0.02414943,  0.00739839,  0.03333126,  0.0515946 , -0.0163026 ,\n",
       "        0.06550607, -0.01794759,  0.07309239,  0.01166206, -0.01817643,\n",
       "        0.00392749,  0.00703375,  0.03426434,  0.02729288, -0.00475265,\n",
       "        0.01720353,  0.04551698, -0.02496281, -0.06664832, -0.02822311,\n",
       "        0.03184071, -0.02069683, -0.03815257,  0.02659006,  0.18702458,\n",
       "       -0.0493904 ,  0.02795539, -0.06647408,  0.02131662,  0.01693988,\n",
       "        0.04659843, -0.04887157, -0.09692122, -0.07950865,  0.06913692,\n",
       "       -0.0173317 ,  0.00877939, -0.06175148,  0.05520935,  0.04833567,\n",
       "        0.00859433,  0.0169889 , -0.02598299,  0.0434835 , -0.03762854,\n",
       "       -0.02821014, -0.00132759, -0.06334166,  0.00318673,  0.01190044,\n",
       "       -0.02857058, -0.01841859, -0.00682279,  0.00447517, -0.01528993,\n",
       "       -0.07283813,  0.00650864,  0.01897584, -0.00431945, -0.02006911,\n",
       "        0.07013839, -0.02700875,  0.04124613, -0.01243533, -0.04903939,\n",
       "       -0.01877775,  0.0053995 , -0.00930875, -0.03993747,  0.01549599,\n",
       "       -0.01568508, -0.05651587,  0.06928204,  0.01355214, -0.0159476 ,\n",
       "        0.04126405,  0.04020314,  0.10078269,  0.02648922,  0.06171743,\n",
       "       -0.01357437,  0.0018341 , -0.00616703,  0.04361626,  0.00650506,\n",
       "        0.05089275, -0.00275116,  0.02991083, -0.11814439, -0.01024311,\n",
       "        0.07333191, -0.02508869,  0.01686102,  0.01045217, -0.07310145,\n",
       "       -0.01285514,  0.09339073, -0.06714858, -0.09901267,  0.0068216 ,\n",
       "        0.03572355, -0.03935919,  0.03302537,  0.02549176,  0.0144202 ,\n",
       "       -0.02991694, -0.01354563, -0.00787938,  0.03613688,  0.05657197,\n",
       "       -0.00474709, -0.02503674, -0.0273344 ,  0.05442371, -0.01384753,\n",
       "        0.00932324, -0.04490621, -0.03971119,  0.02634538, -0.02593908,\n",
       "        0.04915658,  0.04001555, -0.1161194 , -0.08524479, -0.04748566],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft['tarjeta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la distancia entre *embeddings* de t贸kenes similares, por ejemplo debido a un error ortogr谩fico, y la de t贸kenes dis铆miles, de diferente significado.\n",
    "\n",
    "Para ello utilizar茅 la similitud del coseno, una f贸rmula trigonom茅trica que en la definici贸n de `scipy` es igual a cero si ambos vectores apuntan a un mismo lugar; cualquier 谩ngulo existente entre los vectores, arrojar铆a un valor mayor a cero.\n",
    "\n",
    "Los 铆ndices son cateor铆as que nada dicen de la relaci贸n entre las palabras pero los vectores s铆.\n",
    "\n",
    "* https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "distance.cosine(ft['tarjeta'], ft['tarjeta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error ortogr谩fico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18840116262435913"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(ft['tarjeta'], ft['targeta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra palabra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6775485575199127"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(ft['tarjeta'], ft['saldo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguente funci贸n servir谩 para\n",
    "1. obtener los vectores de cada uno de los t贸kenes del vocabulario,\n",
    "2. en el orden de los 铆ndices del vocabulario (es importante mantener este orden),\n",
    "3. convertirlos en tensores de PyTorch (`map` aplica la funci贸n `torch.tensor` a cada uno de los vectores),\n",
    "4. `list` convierte el mapeo es una lista, ya que `map` es *lazy*, no acciona hasta que se lo piden y convertirlo en lista es una manera de pedirlo,\n",
    "5. `torch.stack` apila los tensores de la lista (cada uno tiene dimensi贸n 300 y la lista tiene largo $N$, el tama帽o del vocabulario) en un tensor bidimensional de $N \\times 300$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# versi贸n 1\n",
    "def obtener_embeddings(t贸kenes, fastText):\n",
    "    \n",
    "    embeddings = [fastText[t贸ken] for t贸ken in t贸kenes]\n",
    "\n",
    "    return torch.stack( list( map(torch.tensor, embeddings) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0503, -0.0404,  0.0759,  ...,  0.0252, -0.0356, -0.0142],\n",
       "        [ 0.0093,  0.0350,  0.0453,  ..., -0.0111, -0.0165, -0.0326],\n",
       "        [ 0.0547,  0.0112,  0.1910,  ...,  0.0066, -0.0021, -0.0230],\n",
       "        ...,\n",
       "        [-0.0278, -0.0258,  0.0990,  ...,  0.0018, -0.0074, -0.0465],\n",
       "        [ 0.0149, -0.0274,  0.0268,  ...,  0.0571,  0.0106, -0.0065],\n",
       "        [-0.0097,  0.0221, -0.0038,  ..., -0.0042,  0.0152,  0.0462]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = obtener_embeddings(v.vocabulario, ft)\n",
    "\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces ahora podemos salvarlos para no tener que volver a generarlos, obviando as铆 cargar el modelo de fastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings, 'vectores.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos cargarlos m谩s adelante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.load('vectores.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: bolsa de palabras\n",
    "\n",
    "Hay una forma simple y efectiva de obtener la representaci贸n de un documento, si bien existen otras que son mejores. Los vectores son representaciones de t贸kenes, los documentos son conjuntos de t贸kenes, calcular la suma, el promedio o el m谩ximo de los vectores del conjunto nos da un vector que es la representaci贸n del documento. Como esta agregaci贸n no tiene en cuenta el orden de los t贸kenes en el documento se llama **bolsa de palabras**, o en ingl茅s *bag of words*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 300])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cambio_cien = obtener_embeddings(['se帽or', 'tiene', 'cambio', 'de', 'cien'], ft)\n",
    "\n",
    "cambio_cien.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos la agregaci贸n es en sentido de las columnas, cada columna o dimensi贸n del *embedding* es un atributo o *feature* del t贸ken, queremos obtener los atributos para el documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cambio_cien = torch.mean(cambio_cien, dim=0)\n",
    "\n",
    "cambio_cien.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representaci贸n de una variante del documento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambio_mil = obtener_embeddings(['se帽or', 'tiene', 'cambio', 'de', 'mil'], ft)\n",
    "cambio_mil = torch.mean(cambio_mil, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representaci贸n de un documento bien diferente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrav铆o = obtener_embeddings(['extravi茅', 'mi', 'tarjeta', 'de', 'd茅bito', 'anoche'], ft)\n",
    "extrav铆o = torch.mean(extrav铆o, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos las distancias entre los documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08124548196792603"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(cambio_cien, cambio_mil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39364296197891235"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(cambio_cien, extrav铆o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que `se帽or tiene cambio de cien` est谩 m谩s cerca de `se帽or tiene cambio de mil` que de `extravi茅 mi tarjeta de d茅bito anoche`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la parte 2 hube mencionado a `nn.EmbeddingBag` sin contar su finalidad; es un m贸dulo de PyTorch que hace exactamento esto: recibe un tensor con 铆ndices de t贸kenes de documentos, reemplaza a los 铆ndices por vectores y los agrega en un vector por documento, usando una funci贸n que puede ser `mean`, `max`, `sum`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializar los pesos de la capa de *embeddings*\n",
    "\n",
    "El m茅todo `copy_` carga el tensor de los pesos en el m贸dulo de *embeddings*. Para que la carga funcione las dimensiones del tensor de pesos debe ser exactamente igual a las de la capa. Inicializamosla con cantidad de filas igual al largo del vocabulario y cantidad de columnas igual al tama帽o de los vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingBag(8116, 300, mode=mean)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capa = nn.EmbeddingBag(len(v), ft.get_dimension(), mode='mean')\n",
    "capa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequeamos las dimensiones del tensor de pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8116, 300])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al inicializar la capa, sus pesos se inicializan con valores al azar. Es con el entrenamiento que adquieren valores significativos para red neuronal. Los *embeddings* pre-entrenados sirven justamente para comenzar con valores con sentido, lo que acorta los tiempos de aprendizaje de la red en general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0503, -0.0404,  0.0759,  ...,  0.0252, -0.0356, -0.0142],\n",
       "        [ 0.0093,  0.0350,  0.0453,  ..., -0.0111, -0.0165, -0.0326],\n",
       "        [ 0.0547,  0.0112,  0.1910,  ...,  0.0066, -0.0021, -0.0230],\n",
       "        ...,\n",
       "        [-0.0278, -0.0258,  0.0990,  ...,  0.0018, -0.0074, -0.0465],\n",
       "        [ 0.0149, -0.0274,  0.0268,  ...,  0.0571,  0.0106, -0.0065],\n",
       "        [-0.0097,  0.0221, -0.0038,  ..., -0.0042,  0.0152,  0.0462]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capa.weight.data.copy_(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 119, 142, 2, 1], [1, 119, 142, 2, 1311], [2268, 11, 5, 2, 149, 1443]]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "铆ndices = v.t贸kenes_a_铆ndices([\n",
    "    ['se帽or', 'tiene', 'cambio', 'de', 'cien'],\n",
    "    ['se帽or', 'tiene', 'cambio', 'de', 'mil'],\n",
    "    ['extravi茅', 'mi', 'tarjeta', 'de', 'd茅bito', 'anoche'],\n",
    "])\n",
    "\n",
    "铆ndices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por c贸mo creamos el vocabulario y por c贸mo est谩 definida la clase `Vocab`, el t贸ken `<unk>` de t贸ken desconocido o fuera del vocabulario tiene asignado el 铆ndice `1`; esto ser谩 relevante m谩s adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que a este m贸dulo le gusta que los documentos sean contiguos (un 煤nico documento) y que por otro lado le informemos en qu茅 posiciones de ese documento contiguo comienza cada uno de los documentos.\n",
    "\n",
    "Veamos el largo de cada uno de los documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 6]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len, 铆ndices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer documento siempre comienza en la posici贸n `0`, el segundo lo hace `5` t贸kenes/铆ndices despu茅s, y el tercero en 5 luego del segundo, o sea en la posici贸n `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "posiciones = torch.tensor([0, 5, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convertimos a los documentos en un documento 煤nico y adem谩s en un tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "铆ndices = torch.tensor([\n",
    "    1, 119, 142, 2, 1, 1, 119, 142, 2, 1311, 2268, 11, 5, 2, 149, 1443\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de estos procesamientos la capa ejecuta las mismas operaciones que realizamos manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 300])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectores = capa(铆ndices, posiciones)\n",
    "\n",
    "vectores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que podemos verificar calculando la distancia entre `se帽or tiene cambio de cien` est谩 m谩s cerca de `se帽or tiene cambio de mil`, que manualmente dio $0.081$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1781657338142395"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(vectores[0].detach().numpy(), vectores[1].detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Y no se cumpli贸**. \n",
    "\n",
    "La explicaci贸n est谩 en las palabras fuera del vocabulario. Los *embeddings* pre-entrenados no suelen venir con pesos para t贸kenes especiales como `<unk>` y al hacer `ft['<unk>']`, fastText que est谩 preparado para generar vectores para t贸kenes con los cuales no fue entrenado, devuelve un vector con pesos sin sentido. Es decir, fastText es muy 煤til para obtener vectores aproximados cuando le preguntamos por un t贸ken que no conoce pero que es parecido a otros que s铆, sin embargo `<unk>` no se a parece a ning煤n otro. Nota: Word2Vec y GloVe no tienen soporte para t贸kenes fuera del vocabulario (OOV), en el caso de `<unk>` no hubieran devuelto ning煤n valor.\n",
    "\n",
    "驴Qu茅 podr铆amos haber hecho?\n",
    "* Si contamos con soporte para OOV (fastText), no usar el t贸ken `<unk>` ya que no es necesario. Para ello deber铆amos haber creado el vocabulario inicilizando la clase `Vocab` con el argumento `t贸ken_desconocido=None`.\n",
    "* Si no hay soporte para OOV, salvo que el modelo especifique que cuenta con un vector para el t贸ken especial *desconocido* (y que no necesariamente se simbolizar谩 con `<unk>`), no usar el t贸ken `<unk>` ya que no es posible.\n",
    "* Entrenar vectores desde cero. Al existir `<unk>`, este adquire pesos con el sentido propuesto. No era la idea.\n",
    "* Crear un vector a partir de los existentes, seg煤n est谩 expresado en esta [respuesta de StackOverflow](https://stackoverflow.com/questions/49239941/what-is-unk-in-the-pretrained-glove-vector-files-e-g-glove-6b-50d-txt).\n",
    "\n",
    "### Creando un vector desconocido\n",
    "\n",
    "La respuesta de StackOverflow del 煤ltimo punto sugiere que el **vector promedio de todos los vectores** o, de al menos los que se van a usar, conforman un buen vector desconocido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk = embeddings.mean(dim=0)\n",
    "\n",
    "unk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando un vector de relleno\n",
    "\n",
    "Otro t贸ken especial que consideramos es el relleno, `<pad>`, que sirve para completar los espacios en documentos de distinto largo cuando los queremos agrupar en un tensor. Normalmente los pesos para este vector son todos ceros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = torch.zeros(ft.get_dimension())\n",
    "\n",
    "pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incluyendo los nuevos cambios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# versi贸n 2\n",
    "def obtener_embeddings(t贸kenes, fastText, t贸ken_desconocido='<unk>', t贸ken_relleno='<pad>'):\n",
    "    \n",
    "    embeddings = [fastText[t贸ken] for t贸ken in t贸kenes if t贸ken not in (t贸ken_desconocido, t贸ken_relleno)]\n",
    "    embeddings = torch.stack( list( map(torch.tensor, embeddings) ) )\n",
    "    \n",
    "    if t贸ken_desconocido:\n",
    "        unk = embeddings.mean(dim=0, keepdim=True)\n",
    "        embeddings = torch.cat([unk, embeddings])\n",
    "    \n",
    "    if t贸ken_relleno:\n",
    "        pad = torch.zeros(1, fastText.get_dimension())\n",
    "        embeddings = torch.cat([pad, embeddings])\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0008, -0.0102,  0.0071,  ..., -0.0066,  0.0097, -0.0056],\n",
       "        [ 0.0547,  0.0112,  0.1910,  ...,  0.0066, -0.0021, -0.0230],\n",
       "        ...,\n",
       "        [-0.0278, -0.0258,  0.0990,  ...,  0.0018, -0.0074, -0.0465],\n",
       "        [ 0.0149, -0.0274,  0.0268,  ...,  0.0571,  0.0106, -0.0065],\n",
       "        [-0.0097,  0.0221, -0.0038,  ..., -0.0042,  0.0152,  0.0462]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = obtener_embeddings(v.vocabulario, ft)\n",
    "\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializar los pesos en un modelo\n",
    "\n",
    "Respecto del modelo de la parte 2, la diferencia est谩 en el m茅todo `init_weights` que carga el tensor de los pesos en la capa de *embeddings* y que es llamado durante la inicializaci贸n del modelo. Recordemos: para que la carga funcione (`copy_`) las dimensiones del tensor de pesos debe ser exactamente igual a las de la capa de *embedding*.\n",
    "\n",
    "Adem谩s **congelamos los pesos** (`requires_grad = False`) para que no cambien durante el entrenamiento. Lo que se aconseja es entrenar el resto de las capas hasta que la funci贸n de p茅rdida se estabilice; dejar libres a los pesos de la capa de *embeddings* cuando el resto de la red tiene pesos con valores aleatorios har谩 que los *embeddings* var铆en significativamente durante el aprendizaje y pierdan sentido. Suele ser 煤til descongelar los pesos una vez que el modelo ha alcanzado cierto nivel de aprendizaje para efectuar un aprendizaje fino, en el que los *embeddings* se adaptar谩n al problema en cuesti贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DIM_EMBEDDINGS = 8\n",
    "\n",
    "class ClasificadorBolsa(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False, mode='max')\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "\n",
    "        # inicializamos los pesos\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.embedding.weight.data.copy_(embeddings)\n",
    "        self.embedding.weight.data.requires_grad = False\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Embedding\n",
    "\n",
    "Hemos visto con algo de detalle el m贸dulo de PyTorch `nn.EmbeddingBag`, una capa de doble acci贸n: convierte 铆ndices en vectores y calcula un vector agregado, una forma simple de obtener una representaci贸n de un documento, aunque no la m谩s efectiva de todas. Para lograr mejores representaciones encontramos en uso modelos m谩s complejos. La primera capa de modelos que usan capas LSTM o Transformer es una `nn.Embedding`, que a diferencia de la mencionada anteriormente es de simple acci贸n: convierte 铆ndices en vectores y ya.\n",
    "\n",
    "Quiero ilustrar brevemente c贸mo son la entrada y la salida de esta capa, ya que son bien diferentes a las de `nn.EmbeddingBag`. La inicializaci贸n sin embargo, es similar. El tensor de los pesos tendr谩 las dimensiones de tama帽o del vocabulario por la dimensi贸n (valga la redundancia) de los *embeddings*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "capa = nn.Embedding(len(v), ft.get_dimension(), padding_idx=v.铆ndice_relleno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferentemente, como esta capa requiere el uso del t贸ken de relleno, podemos especificar el 铆ndice del t贸ken para que la capa inicialice sus pesos al azar excepto los de este vector, que ser谩 inicializado en cero. Si lo deseamos, podemos utilizar vectores pre-entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "capa.weight.data.copy_(embeddings)\n",
    "capa.weight.data.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora armaremos un lote de documentos y lo convertiremos en un tensor. Para poder hacer esto 煤ltimo es fundamental que los documentos tengan el mismo largo (que ser谩 igual al del documento m谩s largo), as铆 que nos valdremos del t贸ken de relleno para lograrlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "铆ndices = v.t贸kenes_a_铆ndices([\n",
    "    ['se帽or', 'tiene', 'cambio', 'de', 'cien', '<pad>'],\n",
    "    ['se帽or', 'tiene', 'cambio', 'de', 'mil', '<pad>'],\n",
    "    ['extravi茅', 'mi', 'tarjeta', 'de', 'd茅bito', 'anoche'],\n",
    "])\n",
    "\n",
    "铆ndices = torch.tensor(铆ndices)\n",
    "\n",
    "铆ndices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un tensor bidimensional, la dimensi贸n 0 (filas) es la cantidad de documentos del lote, la dimensi贸n 1 (columnas) es el tama帽o de los documentos.\n",
    "\n",
    "As铆 luce el tensor de 铆ndices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,  119,  142,    2,    1,    0],\n",
       "        [   1,  119,  142,    2, 1311,    0],\n",
       "        [2268,   11,    5,    2,  149, 1443]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "铆ndices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo hacemos pasar por la capa de *embeddings*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 300])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectores = capa(铆ndices)\n",
    "\n",
    "vectores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que la capa anadi贸 una nueva dimensi贸n, ahora tenemos un tensor tridimensional. Reemplaz贸 cada 铆ndice (un escalar) por su vector correspondiente de largo 300. La dimensi贸n 2 (profundidad) siempre corresponder谩 al tama帽o del *embedding*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqu铆 termina la serie de art铆culos de pre-procesamiento de texto. Gracias por haber llegado hasta el fin."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
